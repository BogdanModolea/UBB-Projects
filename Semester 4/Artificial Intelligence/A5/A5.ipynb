{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "input_size = 2\n",
    "output_size = 2\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "   ('hidden', nn.Linear(input_size, 3)),\n",
    "    ('activation1', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(3, output_size)),\n",
    "    ('activation2', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(input_size, 4)),\n",
    "    ('activation1', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(4, output_size)),\n",
    "    ('activation2', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "model3 = nn.Sequential(OrderedDict([\n",
    "    ('hidden1', nn.Linear(input_size, 2)),\n",
    "    ('activation1', nn.Sigmoid()),\n",
    "    ('hidden1', nn.Linear(2, 4)),\n",
    "    ('activation2', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(4, output_size)),\n",
    "    ('activation3', nn.Sigmoid())\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (activation1): Sigmoid()\n",
      "  (output): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (activation2): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (activation1): Sigmoid()\n",
      "  (output): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (activation2): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (hidden1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (activation1): Sigmoid()\n",
      "  (activation2): Sigmoid()\n",
      "  (output): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (activation3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "data_in = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "data_target = torch.tensor([[0., 0.], [0., 1.], [0., 1.], [1., 0.]])\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Train the model\n",
    "bestEpoch = []\n",
    "\n",
    "def train(trainNumber, model):\n",
    "    num_epochs = 10000\n",
    "    found = False\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    print(f\"\\nModel {trainNumber}:\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(data_in)\n",
    "        loss = criterion(outputs, data_target)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        accuracy = (predicted == data_target).float().mean()\n",
    "        \n",
    "        # Print the loss every 1000 epochs\n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy}')\n",
    "\n",
    "        if accuracy == 1.0 and found == False:\n",
    "            #print(f\"Model {trainNumber} reached 100% accuracy at epoch {epoch+1}\")\n",
    "            bestEpoch.append([f\"Model {trainNumber} reached accuracy 100% accuracy at epoch {epoch + 1}\", trainNumber, epoch + 1, model])\n",
    "            found = True\n",
    "    \n",
    "    if found == False:\n",
    "        bestEpoch.append([f\"Model {trainNumber} hasn't reached accuracy 100% in {num_epochs} epochs\", trainNumber, num_epochs, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cdf09ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1:\n",
      "Epoch [1000/10000], Loss: 0.2157, Accuracy: 0.625\n",
      "Epoch [2000/10000], Loss: 0.2105, Accuracy: 0.625\n",
      "Epoch [3000/10000], Loss: 0.2006, Accuracy: 0.625\n",
      "Epoch [4000/10000], Loss: 0.1858, Accuracy: 0.625\n",
      "Epoch [5000/10000], Loss: 0.1700, Accuracy: 0.75\n",
      "Epoch [6000/10000], Loss: 0.1565, Accuracy: 0.875\n",
      "Epoch [7000/10000], Loss: 0.1468, Accuracy: 0.875\n",
      "Epoch [8000/10000], Loss: 0.1403, Accuracy: 0.875\n",
      "Epoch [9000/10000], Loss: 0.1360, Accuracy: 0.875\n",
      "Epoch [10000/10000], Loss: 0.1328, Accuracy: 0.875\n",
      "\n",
      "Model 2:\n",
      "Epoch [1000/10000], Loss: 0.2101, Accuracy: 0.625\n",
      "Epoch [2000/10000], Loss: 0.1952, Accuracy: 0.625\n",
      "Epoch [3000/10000], Loss: 0.1730, Accuracy: 0.75\n",
      "Epoch [4000/10000], Loss: 0.1537, Accuracy: 0.75\n",
      "Epoch [5000/10000], Loss: 0.1411, Accuracy: 0.875\n",
      "Epoch [6000/10000], Loss: 0.1315, Accuracy: 0.875\n",
      "Epoch [7000/10000], Loss: 0.1186, Accuracy: 0.875\n",
      "Epoch [8000/10000], Loss: 0.0980, Accuracy: 1.0\n",
      "Epoch [9000/10000], Loss: 0.0724, Accuracy: 1.0\n",
      "Epoch [10000/10000], Loss: 0.0492, Accuracy: 1.0\n",
      "\n",
      "Model 3:\n",
      "Epoch [1000/10000], Loss: 0.2178, Accuracy: 0.625\n",
      "Epoch [2000/10000], Loss: 0.2172, Accuracy: 0.625\n",
      "Epoch [3000/10000], Loss: 0.2165, Accuracy: 0.625\n",
      "Epoch [4000/10000], Loss: 0.2157, Accuracy: 0.625\n",
      "Epoch [5000/10000], Loss: 0.2147, Accuracy: 0.625\n",
      "Epoch [6000/10000], Loss: 0.2135, Accuracy: 0.625\n",
      "Epoch [7000/10000], Loss: 0.2121, Accuracy: 0.625\n",
      "Epoch [8000/10000], Loss: 0.2104, Accuracy: 0.625\n",
      "Epoch [9000/10000], Loss: 0.2083, Accuracy: 0.75\n",
      "Epoch [10000/10000], Loss: 0.2058, Accuracy: 0.625\n",
      "\n",
      "\n",
      "Model 1 hasn't reached accuracy 100% in 10000 epochs\n",
      "Model 2 reached accuracy 100% accuracy at epoch 7482\n",
      "Model 3 hasn't reached accuracy 100% in 10000 epochs\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# visualize the resuts\n",
    "\n",
    "train(1, model1)\n",
    "train(2, model2)\n",
    "train(3, model3)\n",
    "\n",
    "print('\\n')\n",
    "for best in bestEpoch:\n",
    "    print(best[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0bea66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is model 2\n",
      "\n",
      "Model weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.9575,  2.0631],\n",
      "        [-1.9464, -0.8776],\n",
      "        [-3.4518, -3.4067],\n",
      "        [-2.6753, -2.6139]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 3.2934, -2.9974, -2.9475, -4.0839],\n",
      "        [-0.4214,  0.1016, -3.8873,  2.9128]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# print model wights\n",
    "\n",
    "bestModel = min(bestEpoch, key=lambda x: x[2])\n",
    "print(f\"Best model is model {bestModel[1]}\\n\")\n",
    "\n",
    "print(\"Model weights:\")\n",
    "for x in bestModel[3].children():\n",
    "    if(type(x) == torch.nn.modules.linear.Linear):\n",
    "        print(x.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c65a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
